{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primary data sources on population are a rare resource in developing countries. When existant, civil registration systems are often patchy. Censuses are rare, and at best happening every 10 years. Meanwhile, in countries with democratic constitutions, elections are held on a more frequent basis. In West Africa, most Constitutions require elections for higher offices to be held every five years. Each time elections are held, voting lists have to be updated, to enlist new voters, and distribute voting identifications. Voters lists should record every person allowed to vote in a country, which can in most situation be equated to the adult population. In this regard, voters list could constitute an interesting data source, providing a regular update on the adult population of a country.\n",
    "\n",
    "In 2015 and 2016, [27 african countries have planned presidential elections](http://libeafrica4.blogs.liberation.fr/2016/04/20/peut-en-cartographier-2016-la-grande-annee-electorale-en-afrique/), and more have planned local or legislative elections (list [for 2015](http://www.jeuneafrique.com/43179/politique/carte-interactive-o-et-quand-se-tiennent-les-lections-de-2015-en-afrique/) and [for 2016](http://www.jeuneafrique.com/mag/284560/politique/carte-elections-a-venir-afrique-cest-lalternance/). Some researchers and journalists have questioned the [credibility and regularity of some of these elections](http://www.lam.sciencespobordeaux.fr/page/afrique-presidentielles), as they question the way electoral lists are designed, suspecting partisan biases in the way voters are identified and registered. Meanwhile the systematic registration and identification of a sizeable chunk of populations, even if imperfect, should be considered as a huge opportunity to get or update data on these populations.\n",
    "\n",
    "The update of electoral lists is indeed often a conflictual and highly politicized process. In African countries where vote is often overdetermined by geographic and ethnic origins of voters, suspicions of fraud are frequent, with under recording of some categories of voters, and over recording of other categories. Meanwhile, with the development of [better techniques for voters identification](https://regardexcentrique.wordpress.com/2015/06/10/la-biometrie-electorale-en-afrique-dossier/#_ftn1), and with the development of supervision by civil societies and international agencies, one can hope the completeness and quality of voters lists should be acceptable. Moreover, in order to improve transparence of electoral processes, voters lists are often made available for the public to control and correct.\n",
    "\n",
    "## The Niger 2016 elections\n",
    "\n",
    "In Niger, presidential and parlementary elections were held in February 2016. Voters lists were updated during the second half of the year 2015, under the supervision and control of a mission of the Office International de la Francophonie (OIF). The operations for registration of voters [were conducted during the third quarter of 2015](http://www.ceni-niger.org/article-region/#more-24). A first version of the voters list was [published on December 21, 2015](http://www.ceni-niger.org/article-region/#more-24), tallying 7,569,172 voters, out of 8,569,309 that were expected [based on the 2012 census](http://www.iinanews.org/page/public/news_details.aspx?id=98929&NL=True#)\n",
    "\n",
    "Final lists were validated in early January 2016 after [being corrected](http://www.nigerdiaspora.net/les-infos-du-pays/politique-niger/politique-niger/item/72543-synthese-du-rapport-de-l-audit-du-fichier-electoral-le-guri-systeme-a-visage-decouvert-adieu-le-coup-k-o) for [some incoherencies](http://www.nigerinter.com/2016/01/le-fichier-electoral-du-niger-valable-sous-reserves/) noted by the supervisory body. [A final report on these lists](http://www.nigerinter.com/2016/05/remise-officielle-du-rapport-du-fichier-electoral-au-ministre-detat-a-linterieur-par-le-cfeb/) was published in may 2016. \n",
    "\n",
    "The Comission Electorale Nationale Independante (CENI) later made these lists fully available on its website.\n",
    "\n",
    "This work purposes to evaluate how the information made available in voters lists compares with other data sources on Nigerien's population, and how it brings additional knowledge on this population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Two main data sources are used in this work :\n",
    "1. The list of electors, extracted from the CENI website\n",
    "2. A geolocalized repertoire of all localities and there population, produced during Niger's latest Census\n",
    "\n",
    "## Voters List\n",
    "\n",
    "The voters' list was extracted from the [CENI's website](http://www.ceni-niger.org/) using Python's web extraction package _BeautifulSoup_. The extraction first navigated the CENI's website to get the hierarchy of Regions, Departments, Communes and Voting Stations. In a second step, each voting station voting list was read and saved in tabular format in separate files. The lists were then anonymized and compiled in a central file. \n",
    "\n",
    "For each voter, the covariates collected were : voting stations, commune, department and region, date of birth, profession. \n",
    "\n",
    "Data was obtained for 7,617,613 voters.\n",
    "\n",
    "\n",
    "## Census / Répertoire National des Localités\n",
    "\n",
    "The _Répertoire National des Localités_ (RENALOC) was downloaded as a pdf file from the [Institut National de la Statistique (INS) website](http://www.stat-niger.org/). The tables were extracted in bulk from this file using the Tabula Package, and then processed in Python to recompose the geographic structure of the document.\n",
    "\n",
    "The final data consists in 34507 localities, for which the INS provides the number of inhabitants, by gender, as well as the number of households, and the number of agricultural households. For most of the localities, a GPS coordinate is recorded, as well as the type of locality (neighborhood, village, camp, water well, hamlet).\n",
    "\n",
    "## Additional Data sources\n",
    "\n",
    "Administrative boundaries for regions and departements were retrieved from the CENI's website. Boundaries for communes were retrieved from colleagues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Matching\n",
    "\n",
    "All data sources (voters list, RENALOC, administrative boundaries) have been matched at commune level. For mapping purposes, some urban areas had to be collapsed at city level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "## Age Structure Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Usual Suspects\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "## sklearn tools we will use\n",
    "from sklearn import datasets , preprocessing\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "## Additional analytic tools\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "## For parralell computing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "## IPython Display settings\n",
    "import warnings\n",
    "from IPython.core.display import HTML, display\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "plotting = False\n",
    "\n",
    "## Voters data\n",
    "#voters_data = pd.read_csv('../data/processed/voters_list.csv' , encoding = \"ISO-8859-1\")\n",
    "#voters_data = voters_data[(voters_data.age >= 18) & (voters_data.NOM_REGION != 'DIASPORA')]\n",
    "\n",
    "## Featured data\n",
    "model_data = pd.read_csv('../data/processed/commune_collapsed_matched.csv' , encoding = \"ISO-8859-1\")\n",
    "model_data['urbain'] = list((model_data['commune'].str[0:14] == 'ARRONDISSEMENT') | (model_data['commune'] == model_data['region']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the hypothesis that completeness of voting lists is random in each age group and model the population at commune level as :\n",
    "\n",
    "$$Y_c = N(\\beta_0 + \\beta_r + \\beta_1 f(v_c) + \\beta_2 sr_c + \\beta_3 urb_c + \\beta_4 age_c  + \\beta_5 vot_c)$$\n",
    "\n",
    "With :\n",
    "* $\\beta_0$ a constant \n",
    "* $\\beta_r$ a regional fixed effect\n",
    "* $f_c(v_c)$ a transformation of the number of registered voters to impute non adult population. This imputation is made at commune level using splines\n",
    "* $sr_c$ the percentage of women in the commune\n",
    "* $urb_c$ a dummy variable depicting wether the commune is a urban commune or not (aka arrondissement\n",
    "* $age_c$ is the average age in the commune\n",
    "* $vot_c$ is the number of people registered on the voting lists who actually voted in the first round of the presidential election \n",
    "\n",
    "We first get the distributions of ages in each commune. As only adults are registered on voting lists, we have to impute the distribution of younger age groups. We do so by fitting a spline on the proportion of voters of each age. To obtain the uncertainty this imputation, we use boostrap, and resample the voter list at commune level. We thus estimate $f(v_c)$ as :\n",
    "\n",
    "$$f(v_c) = N(v_c + v^{*}_{k})$$\n",
    "\n",
    "Where $v^{*}_{k}$ is the imputed number of non adults in the commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boot_splines = pickle.load( open( \"../data/processed/bootstraped_splines.p\", \"rb\" ) )\n",
    "\n",
    "data_bootstrapped = pd.DataFrame(boot_splines[0][1]).T\n",
    "for i in range(len(boot_splines)):\n",
    "    commune = boot_splines[i]\n",
    "    dat = pd.DataFrame(commune[0]).T\n",
    "    for j in range(1 , len(commune)) :\n",
    "        if ~([i,j] == [0,1]) :\n",
    "            dat = dat.append(pd.DataFrame(commune[j]).T)\n",
    "    data_bootstrapped = data_bootstrapped.append(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spline_95IC(out_spline):\n",
    "    ext5 = pd.DataFrame(list(out_spline['extrapolated'])).quantile(q=0.05, axis=0, numeric_only=True, interpolation='linear')\n",
    "    ext95 = pd.DataFrame(list(out_spline['extrapolated'])).quantile(q=0.95, axis=0, numeric_only=True, interpolation='linear')\n",
    "    \n",
    "    spl5 = pd.DataFrame(list(out_spline['splinned'])).quantile(q=0.05, axis=0, numeric_only=True, interpolation='linear')\n",
    "    spl95 = pd.DataFrame(list(out_spline['splinned'])).quantile(q=0.95, axis=0, numeric_only=True, interpolation='linear')\n",
    "    return ([ext5 , ext95] , [spl5 , spl95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "level = ['region' , 'departement' , 'commune']\n",
    "#level = 'region'\n",
    "\n",
    "ICSplined = data_bootstrapped.groupby(level).apply(get_spline_95IC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ICSplined = ICSplined.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ICSplined.columns = level + ['IC95']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolating non adult age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if level == ['region' , 'departement' , 'commune'] :\n",
    "    nrow = 38\n",
    "    ncol = 7\n",
    "\n",
    "if level == 'region' :\n",
    "    nrow = 3\n",
    "    ncol = 3\n",
    "\n",
    "    plotting = True\n",
    "    \n",
    "if plotting == True :\n",
    "    f, axarr = plt.subplots(nrow, ncol,figsize=(80,400))\n",
    "    col = row = 0\n",
    "    for commune in list(extrapolated_data.keys()) :\n",
    "        extr = extrapolated_data[commune]\n",
    "        axarr[row , col].plot(age_dist[(age_dist.NOM_COMMUNE == extr['commune']) & (age_dist.NOM_REGION == extr['region'])].age , \n",
    "                          age_dist[(age_dist.NOM_COMMUNE == extr['commune']) & (age_dist.NOM_REGION == extr['region'])].percentage, 'ro', ms=5 )\n",
    "        \n",
    "        ic = ICSplined[(ICSplined.region == extr['commune']) & (ICSplined.region == extr['region'])]\n",
    "        \n",
    "        axarr[row , col].plot(list(range(len(extr['extrapolated']) , 101)) , extr['splinned'], 'b', lw=3)\n",
    "        axarr[row , col].plot(list(range(len(extr['extrapolated']) , 101)) , list(ICSplined.IC95[0][1][0]), 'b', lw=3, ls = 'dashed')\n",
    "        axarr[row , col].plot(list(range(len(extr['extrapolated']) , 101)) , list(ICSplined.IC95[0][1][1]), 'b', lw=3, ls = 'dashed')\n",
    "        \n",
    "        axarr[row , col].plot(list(range(0 , len(extr['extrapolated']))) , extr['extrapolated'], 'g', lw=3 )\n",
    "        axarr[row , col].plot(list(range(0 , len(extr['extrapolated']))) , list(ICSplined.IC95[0][0][0]), 'g', lw=3 , ls = 'dashed')\n",
    "        axarr[row , col].plot(list(range(0 , len(extr['extrapolated']))) , list(ICSplined.IC95[0][0][1]), 'g', lw=3 , ls = 'dashed')\n",
    "        \n",
    "        axarr[row , col].set_title(commune)\n",
    "        col = col + 1\n",
    "        if col > (ncol - 1) :\n",
    "            col = 0\n",
    "            row = row + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Size estimation\n",
    "### Just summing extrapolated age data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_N_voters(data) :\n",
    "    \"\"\"\n",
    "    Getting number of voters in a \n",
    "    \"\"\"\n",
    "    return len(data)\n",
    "\n",
    "N_Voters = voters_data.groupby(['NOM_REGION' , 'NOM_DEPART' , 'NOM_COMMUNE']).apply(get_N_voters).reset_index()\n",
    "N_Voters.columns = ['region' , 'departement' , 'commune' , 'n_voters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputed_voters = pd.merge(data_bootstrapped , N_Voters , on = ['region' , 'departement' , 'commune'] , how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Impute_Extra_Kids(N_Voters , extrapolated_data = extrapolated_data):\n",
    "    pop = N_Voters.n_voters\n",
    "    uu = N_Voters.region[list(N_Voters.index)[0]] + '_' + N_Voters.commune[list(N_Voters.index)[0]]\n",
    "    total_pop = sum(extrapolated_data[uu]['extrapolated'] + extrapolated_data[uu]['splinned']) * pop\n",
    "    return total_pop[list(total_pop.index)[0]]\n",
    "\n",
    "total_pop = N_Voters.groupby(['region' , 'departement' , 'commune']).apply(Impute_Extra_Kids).reset_index()\n",
    "total_pop.columns = ['region' , 'departement' ,  'commune' , 'extrapolated_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_data = pd.merge(model_data , total_pop , on = ['region' , 'departement' , 'commune'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.asarray(model_data.population_census)\n",
    "\n",
    "x_cat = model_data[['region' , 'urbain' , 'departement']].T.to_dict().values()\n",
    "\n",
    "\n",
    "v = DictVectorizer(sparse=False)\n",
    "x_cat = v.fit_transform(x_cat)\n",
    "\n",
    "x_train = np.hstack((model_data[['population_voting_list' , 'mean_age' , 'voting']] , x_cat ))\n",
    "\n",
    "## Linear Regression\n",
    "lr = linear_model.LinearRegression()\n",
    "predicted_lr = cross_val_predict(lr, x_train  , y, cv=10)\n",
    "\n",
    "error = (predicted_lr - y)  / y\n",
    "\n",
    "dat = pd.DataFrame({'y':y , 'error':error , 'region':model_data.region , 'commune':model_data.commune , 'predicted':predicted_lr})\n",
    "\n",
    "nrow = 4\n",
    "ncol = 2\n",
    "\n",
    "if plotting == True :\n",
    "    f, axarr = plt.subplots(nrow, ncol,figsize=(15,15))\n",
    "    col = row = 0\n",
    "    for region in list(dat['region'].unique()) :\n",
    "        axarr[row , col].plot(dat.y[dat['region'] == region] , \n",
    "                          dat.predicted[dat['region'] == region], 'ro', ms=5 )\n",
    "        axarr[row , col].plot([0 , max([max(dat.y[dat['region'] == region]) , max(dat.predicted[dat['region'] == region])])] , [0 , max([max(dat.y[dat['region'] == region]) , max(dat.predicted[dat['region'] == region])])] ,'k-')\n",
    "        axarr[row , col].set_xlim(0,(max([max(dat.y[dat['region'] == region]) , max(dat.predicted[dat['region'] == region])]) + 1000))\n",
    "        axarr[row , col].set_ylim(0,(max([max(dat.y[dat['region'] == region]) , max(dat.predicted[dat['region'] == region])]) + 1000))\n",
    "        axarr[row , col].set_title(region)\n",
    "        col = col + 1\n",
    "        if col > (ncol - 1) :\n",
    "            col = 0\n",
    "            row = row + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(error, 40, normed=1, facecolor='green', alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = np.hstack((model_data[['extrapolated_data' , 'mean_age' , 'voting' ]] , x_cat ))\n",
    "\n",
    "## Linear Regression\n",
    "lr = linear_model.LinearRegression()\n",
    "predicted_lr = cross_val_predict(lr, x_train  , y, cv=10)\n",
    "\n",
    "error = (predicted_lr - y)  / y\n",
    "\n",
    "dat = pd.DataFrame({'y':y , 'error':error , 'region':model_data.region , 'commune':model_data.commune , 'predicted':predicted_lr})\n",
    "\n",
    "nrow = 4\n",
    "ncol = 2\n",
    "\n",
    "if plotting == True :\n",
    "    f, axarr = plt.subplots(nrow, ncol,figsize=(15,15))\n",
    "    col = row = 0\n",
    "    for region in list(dat['region'].unique()) :\n",
    "        axarr[row , col].plot(dat.y[dat['region'] == region] , \n",
    "                          dat.predicted[dat['region'] == region], 'ro', ms=5 )\n",
    "        axarr[row , col].plot([0 , max([max(dat.y[dat['region'] == region]) , max(dat.predicted[dat['region'] == region])])] , [0 , max([max(dat.y[dat['region'] == region]) , max(dat.predicted[dat['region'] == region])])] ,'k-')\n",
    "        axarr[row , col].set_xlim(0,(max([max(dat.y[dat['region'] == region]) , max(dat.predicted[dat['region'] == region])]) + 1000))\n",
    "        axarr[row , col].set_ylim(0,(max([max(dat.y[dat['region'] == region]) , max(dat.predicted[dat['region'] == region])]) + 1000))\n",
    "        axarr[row , col].set_title(region)\n",
    "        col = col + 1\n",
    "        if col > (ncol - 1) :\n",
    "            col = 0\n",
    "            row = row + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(error, 40, normed=1, facecolor='green', alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = smf.mixedlm('population_census ~ population_voting_list + mean_age + voting + urbain ', data=model_data , groups=model_data['region']).fit()\n",
    "\n",
    "# Inspect the results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_variables_def(results) :\n",
    "    \"\"\"\n",
    "    Function that goes through a statsmodel summary and returns list of variables and values to include in prediction\n",
    "    \"\"\" \n",
    "    variables = list(results.params.keys())\n",
    "    variable_list = {}\n",
    "    for var in variables :\n",
    "        value = ''\n",
    "        out = {'variable':var}\n",
    "        var_split = var.split('[')\n",
    "        if len(var_split) > 1 :\n",
    "            value = var_split[1].replace(']' , '').replace('T.' , '')\n",
    "            out = {'variable':var_split[0] , 'value':value , 'parametre':var}\n",
    "        variable_list[var] = out\n",
    "    return variable_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pred_random_effect(re_model , test_data , random_effect):\n",
    "    \"\"\"\n",
    "    Function that returns the response of a statsmodel random effect linear model\n",
    "    \"\"\"\n",
    "    test_data['Intercept'] = test_data['Intercept RE'] = 1\n",
    "    params = re_model.params\n",
    "    variables = get_variables_def(re_model)\n",
    "    out = 0\n",
    "    for var in list(variables.keys()) :\n",
    "        v = variables[var]\n",
    "        if len(v) > 1 :\n",
    "            out = out + params[v['parametre']]*(str(test_data[v['variable']]) == v['value'])\n",
    "        if len(v) == 1 :\n",
    "            out = out + params[v['variable']]*test_data[v['variable']]\n",
    "    \n",
    "    if len(test_data[random_effect].unique()) > len(results.random_effects.Intercept) :\n",
    "        missing = test_data.loc[(test_data[random_effect].isin(list(results.random_effects.Intercept.index)) == False) , random_effect].unique()\n",
    "        for reg in missing :\n",
    "            print(missing + ' is missing')\n",
    "            re_model.random_effects.Intercept[reg] = 0\n",
    "    \n",
    "    random_effects = list(re_model.random_effects.Intercept[test_data.loc[: , random_effect]])\n",
    "    \n",
    "    out =  out + random_effects\n",
    "       \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def k_fold_validation(n_folds , data , model , random_effect):\n",
    "    \"\"\"\n",
    "    Function that performs k_fold validation computations for random effect \n",
    "    \"\"\"\n",
    "    samp = np.random.choice(len(data), len(data) , replace = False)\n",
    "    test_out = ''\n",
    "    for i in range(1,(n_folds + 1)):\n",
    "        out = samp[((i- 1)*(len(data)/n_folds)):((i)*(len(data)/n_folds))]\n",
    "        train_dat = data[~data.index.isin(out)]\n",
    "        test_dat = data[data.index.isin(out)]\n",
    "        results = smf.mixedlm(model , data = train_dat , groups = train_dat[random_effect]).fit()\n",
    "        test_dat['prediction'] = pred_random_effect(results , test_dat , random_effect)\n",
    "        if len(test_out) > 0 :\n",
    "            test_out = test_out.append(test_dat)\n",
    "        elif len(test_out) == 0 :\n",
    "            test_out = test_dat       \n",
    "    return test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(data , predicted):\n",
    "    return np.sqrt(np.average(((data - predicted) * (data - predicted))))\n",
    "rmses = []\n",
    "n_folds = 2\n",
    "final_test = k_fold_validation(n_folds , model_data , 'population_census ~ population_voting_list + mean_age + voting + urbain + prop_women' , 'region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_run(t) :\n",
    "    final_test = 'final'\n",
    "    final_test = k_fold_validation(4 , model_data , 'population_census ~ population_voting_list + mean_age + voting + urbain + prop_women' , 'region')\n",
    "    return final_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bootstrap_samples(data , i) :\n",
    "    u = data.reset_index().iloc[i]\n",
    "    return u\n",
    "\n",
    "def get_kids_population_from_bootstrap(data):\n",
    "    data['imputed_population'] = sum(data['extrapolated'].iloc[0]) * data['n_voters'].iloc[0] + data['n_voters'].iloc[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_validation(j , model):\n",
    "    imputed_samp = imputed_voters.groupby([ 'region' , 'departement' , 'commune']).apply(get_bootstrap_samples , i=(j,))\n",
    "    del imputed_samp['region']\n",
    "    del imputed_samp['departement']\n",
    "    del imputed_samp['commune']\n",
    "    imputed_samp = imputed_samp.reset_index()\n",
    "    del imputed_samp['index']\n",
    "    imputed_samp = imputed_samp.groupby(['region','departement','commune']).apply(get_kids_population_from_bootstrap)\n",
    "    model_samp = pd.merge(model_data , imputed_samp , on = [\"region\",\"departement\",\"commune\"])\n",
    "    test_out = k_fold_validation(n_folds , model_samp , model , 'region')\n",
    "    rmses = rmse(test_out.population_census , test_out.prediction)\n",
    "    return {'result_test':test_out , 'rmses':rmses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = Parallel(n_jobs=4, verbose=10 , backend = 'threading')(delayed(get_validation)(i , 'population_census ~ imputed_population + mean_age + voting + urbain + prop_women') for i in range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rsmes = []\n",
    "for i in range(len(out)):\n",
    "    rsmes = rsmes + [out[i]['rmses']]\n",
    "    \n",
    "rsmes = [x for x in rsmes if str(rsmes) if (pd.isnull(x) != True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(rsmes , 10  , facecolor='green' , alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_boot_95(data):\n",
    "    q025 = data.prediction.dropna().quantile(0.025)\n",
    "    q500 = data.prediction.dropna().quantile(0.5)\n",
    "    q975 = data.prediction.dropna().quantile(0.975)\n",
    "\n",
    "    return pd.DataFrame({'q025':q025 , 'q500':q500 , 'q975':q975} , index = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = out[0]['result_test']\n",
    "for i in range(1,len(out)):\n",
    "    data = data.append(out[i]['result_test'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def coverage_95(data):\n",
    "    data = data.iloc[0]\n",
    "    data['cov_ic95'] = ((data['q025']< data['population_census']) & (data['q975'] < data['population_census']))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cov95 = data.groupby(['region' , 'departement' , 'commune']).apply(get_boot_95)\n",
    "cov95 = cov95.reset_index()\n",
    "del cov95['level_3']\n",
    "cov95 = pd.merge(model_data , cov95 , left_on = ['region' , 'departement' , 'commune'] , right_on = ['region' , 'departement' , 'commune'] , how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cov = cov95.groupby(['region' , 'commune']).apply(coverage_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coverage(data):\n",
    "    return data['cov_ic95'].sum() / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cov.groupby(['region']).apply(coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Maps\n",
    "\n",
    "## Age structure reconstitution\n",
    "\n",
    "## Population Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
